{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c67d7e9a",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6c9d718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from timeit import default_timer as timer \n",
    "\n",
    "\n",
    "df = pd.read_csv('bank_data_train.csv', skiprows=1)\n",
    "trainArray = df.to_numpy()\n",
    "\n",
    "\n",
    "file = open('bank_data_train.csv')\n",
    "reader = csv.reader(file);\n",
    "file.close()\n",
    "\n",
    "df = pd.read_csv('bank_data_test.csv', skiprows=1)\n",
    "finalTestingData = df.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "212ffdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_str_to_index(dataset, columnIndex):\n",
    "    unique = list()\n",
    "    for row in dataset:\n",
    "        s = str(row[columnIndex])\n",
    "        if (s == 'nan'):\n",
    "            continue\n",
    "        s = s.lower()\n",
    "        if (s not in unique):\n",
    "            unique.append(s)\n",
    "        row[columnIndex] = unique.index(s)\n",
    "\n",
    "def change_columns_to_int(dataset, columns):\n",
    "    for column in columns:\n",
    "        change_str_to_index(dataset, column)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc0507f",
   "metadata": {},
   "source": [
    "# Naiv Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2efe13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate data by class\n",
    "#this function assumes that the last column of the table is the class\n",
    "from math import sqrt\n",
    "from math import exp\n",
    "from math import pi\n",
    "\n",
    "def separate_by_class(dataset):\n",
    "\tseparated = dict()\n",
    "\tfor i in range(len(dataset)):\n",
    "\t\tvector = dataset[i]\n",
    "\t\tclass_value = vector[-1]\n",
    "\t\tif (class_value not in separated):\n",
    "\t\t\tseparated[class_value] = list()\n",
    "\t\tseparated[class_value].append(vector)\n",
    "\treturn separated\n",
    "\n",
    "\n",
    "#count non nan elements\n",
    "def len_nan(numbers):\n",
    "    return (np.count_nonzero(~np.isnan(numbers)))\n",
    "\n",
    "\n",
    "#claculate the mean of a list of numbers ignoring nan elements\n",
    "def mean_nan(numbers, size):\n",
    "    return np.nansum(numbers)/ size\n",
    "\n",
    "\n",
    "#claculate the standard deviation of a list of numbers ignoring nan elements\n",
    "def stdev_nan(numbers, mean, size):\n",
    "    variance = np.nansum(np.array([(x - mean)**2 for x in numbers], dtype=np.float64)) / size\n",
    "    return sqrt(variance)\n",
    "\n",
    "\n",
    "#claculate the size of each column ignoring nan values\n",
    "def get_header_size(classes):\n",
    "    sizes = [0] * len(classes[0][0])\n",
    "    for blob in classes:\n",
    "        for i in range(len(classes[0][0])):\n",
    "            sizes[i] += len_nan(get_column(classes[blob], i))\n",
    "    return sizes\n",
    "\n",
    "# summarise the data for each metric in the dataset\n",
    "# claculate the mean, dev and count for each column\n",
    "def summarize_dataset(dataset):\n",
    "    out = []\n",
    "    for column in zip(*dataset):\n",
    "        arr = np.array(column, dtype=np.float64)\n",
    "        size = len_nan(arr)\n",
    "        mean = mean_nan(arr, size)\n",
    "        dev = stdev_nan(arr, mean, size)\n",
    "        out.append([mean, dev, size])\n",
    "    return out\n",
    "\n",
    "#split the dataset in classes based on the last column\n",
    "#then substetute each class with the summarized values\n",
    "def summarize_by_class(separated):\n",
    "\tsummaries = dict()\n",
    "\tfor class_value, rows in separated.items():\n",
    "\t\tsummaries[class_value] = summarize_dataset(rows)\n",
    "\treturn summaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32ab3ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#P(class=0|X1,X2) = P(X1|class=0) * P(X2|class=0) * P(class=0)\n",
    "# Calculate the probabilities of predicting each class for a given row\n",
    "\n",
    "from math import sqrt\n",
    "from math import pi\n",
    "from math import exp\n",
    "import scipy.stats\n",
    "\n",
    "def calculate_class_probabilities(summaries, row):\n",
    "    probabilities = dict()\n",
    "    total_rows = sum([summaries[label][0][2] for label in summaries])\n",
    "    for class_value, class_summaries in summaries.items():\n",
    "        probabilities[class_value] = summaries[class_value][0][2] / float(total_rows)\n",
    "        for i in range(1,len(class_summaries), 1):\n",
    "            mean, stdev, count = class_summaries[i]\n",
    "            if (np.isnan(row[i])):\n",
    "                proba = 1\n",
    "            else:\n",
    "                proba = scipy.stats.norm(mean, stdev).pdf(row[i])\n",
    "            if (np.isnan(proba)):\n",
    "                proba = 1\n",
    "            #print(i, '=> ', proba)\n",
    "            probabilities[class_value] *= proba\n",
    "    return probabilities\n",
    "\n",
    "def predict_naive_class(summaries, row):\n",
    "    res = calculate_class_probabilities(summaries, row)\n",
    "    if (res[0] >= res[1]):\n",
    "        return (0)\n",
    "    else:\n",
    "        return (1)\n",
    "\n",
    "# Calculate accuracy percentage\n",
    "def calculate_accuracy(testSet, classifier):\n",
    "    correct = 0\n",
    "    length = len(testSet) / 10\n",
    "    i = 0\n",
    "    for row in testSet:\n",
    "        if (predict_naive_class(classifier, row) == row[-1]):\n",
    "            correct += 1\n",
    "        i += 1\n",
    "        if (i >= length):\n",
    "            print('=', flush=True, end=\"\")\n",
    "            i = 0\n",
    "    return correct / float(len(testSet)) * 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac27296",
   "metadata": {},
   "source": [
    "# Tie All Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c35e015",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prep data\n",
    "change_columns_to_int(trainArray, [13, 19, 24, 25, 27, 28, 30, 36, 39, 42, 53, 66, 88])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68a8b558",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data to classes\n",
    "classes = separate_by_class(trainArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "325926fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326264 65252\n",
      "261012 65252\n",
      "28925 5785\n",
      "23140 5785\n"
     ]
    }
   ],
   "source": [
    "#split int 80-20 for training-testing\n",
    "import random\n",
    "testSet = []\n",
    "\n",
    "for index in classes:\n",
    "    size = int(len(classes[index]) * 0.2)\n",
    "    print(len(classes[index]), size)\n",
    "    random.shuffle(classes[index])\n",
    "    testSet.extend(classes[index][:size])\n",
    "    classes[index] = classes[index][size:]\n",
    "    print(len(classes[index]), size)\n",
    "random.shuffle(testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f1b76d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 25.82422489998862\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "baseline = summarize_by_class(classes)\n",
    "print(\"time:\", timer()-start)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "859d192c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=="
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\Anaconda3\\envs\\tf2.9\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:1904: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  x = np.asarray((x - loc)/scale, dtype=dtyp)\n",
      "C:\\Users\\acer\\Anaconda3\\envs\\tf2.9\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:1904: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  x = np.asarray((x - loc)/scale, dtype=dtyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========without GPU: 8.831762899993919\n",
      "accuracy =  80.0\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer \n",
    "\n",
    "start = timer()\n",
    "acc = calculate_accuracy(testSet[:100], baseline)\n",
    "print(\"without GPU:\", timer()-start)\n",
    "print(\"accuracy = \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309d935b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
