{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c67d7e9a",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6c9d718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from timeit import default_timer as timer\n",
    "from numba import jit, njit\n",
    "from numba.typed import List\n",
    "\n",
    "\n",
    "df = pd.read_csv('bank_data_train.csv', skiprows=1)\n",
    "trainArray = df.to_numpy()\n",
    "\n",
    "file = open('bank_data_train.csv')\n",
    "reader = csv.reader(file);\n",
    "file.close()\n",
    "\n",
    "df = pd.read_csv('bank_data_test.csv', skiprows=1)\n",
    "finalTestingData = df.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "212ffdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_str_to_index(dataset, columnIndex):\n",
    "    unique = list()\n",
    "    for row in dataset:\n",
    "        s = str(row[columnIndex])\n",
    "        if (s == 'nan'):\n",
    "            continue\n",
    "        s = s.lower()\n",
    "        if (s not in unique):\n",
    "            unique.append(s)\n",
    "        row[columnIndex] = unique.index(s)\n",
    "\n",
    "def change_columns_to_int(dataset, columns):\n",
    "    for column in columns:\n",
    "        change_str_to_index(dataset, column)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc0507f",
   "metadata": {},
   "source": [
    "# Naiv Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2efe13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate data by class\n",
    "#this function assumes that the last column of the table is the class\n",
    "from math import sqrt\n",
    "from math import exp\n",
    "from math import pi\n",
    "from numba import jit, njit\n",
    "\n",
    "#separate the data into classes according to the last value in each row\n",
    "def separate_by_class(dataset):\n",
    "\tseparated = dict()\n",
    "\tfor i in range(len(dataset)):\n",
    "\t\tvector = dataset[i]\n",
    "\t\tclass_value = vector[-1]\n",
    "\t\tif (class_value not in separated):\n",
    "\t\t\tseparated[class_value] = list()\n",
    "\t\tseparated[class_value].append(vector)\n",
    "\treturn separated\n",
    "\n",
    "\n",
    "#count non nan elements\n",
    "@njit\n",
    "def len_nan(numbers):\n",
    "    return (np.count_nonzero(~np.isnan(numbers)))\n",
    "\n",
    "\n",
    "#claculate the mean of a list of numbers ignoring nan elements\n",
    "@njit\n",
    "def mean_nan(numbers, size):\n",
    "    return np.nansum(numbers)/ size\n",
    "\n",
    "\n",
    "#claculate the standard deviation of a list of numbers ignoring nan elements\n",
    "@njit\n",
    "def stdev_nan(numbers, mean, size):\n",
    "    variance = np.nansum(np.array([(x - mean)**2 for x in numbers], dtype=np.float64)) / size\n",
    "    return sqrt(variance)\n",
    "\n",
    "#get column of 2d array\n",
    "@jit\n",
    "def get_column(matrix, i):\n",
    "    return [row[i] for row in matrix]\n",
    "\n",
    "\n",
    "# Calculate the Gaussian probability distribution function for x\n",
    "@njit\n",
    "def normal(mean, stdev, val):\n",
    "    exponent = exp(-((val-mean)**2 / (2 * stdev**2 )))\n",
    "    return (1 / (sqrt(2 * pi) * stdev)) * exponent\n",
    "\n",
    "\n",
    "# summarise the data for each metric in the dataset\n",
    "# claculate the mean, dev and count for each column\n",
    "def summarize_dataset(dataset, n):\n",
    "    i = 0\n",
    "    sizes = np.zeros(n, dtype = np.float64)\n",
    "    means = np.zeros(n, dtype = np.float64)\n",
    "    devs = np.zeros(n, dtype = np.float64)\n",
    "    for column in zip(*dataset):\n",
    "        arr = np.array(column, dtype=np.float64)\n",
    "        size = len_nan(arr)\n",
    "        mean = mean_nan(arr, size)\n",
    "        dev = stdev_nan(arr, mean, size)\n",
    "        sizes[i] = size\n",
    "        means[i] = mean\n",
    "        devs[i] = dev\n",
    "        i += 1\n",
    "    return (sizes, means, devs)\n",
    "\n",
    "#substitute each class with the summarized values\n",
    "def summarize_each_class(separated):\n",
    "    summaries = dict()\n",
    "    n = len(separated[0][0])\n",
    "    for class_value, rows in separated.items():\n",
    "        summaries[class_value] = summarize_dataset(rows, n)\n",
    "    return summaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ed5719a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#P(class=0|X1,X2) = P(X1|class=0) * P(X2|class=0) * P(class=0)\n",
    "# Calculate the probabilities of row belonging to a class\n",
    "@njit\n",
    "def calculate_class_probability(row, sizes, means, devs):\n",
    "    proba = 1.0\n",
    "    for i in range(1, len(row), 1):\n",
    "        if (devs[i] == 0):\n",
    "            continue\n",
    "        tmp = normal(means[i], devs[i], row[i])\n",
    "        if (np.isnan(tmp)):\n",
    "            tmp = 1.0\n",
    "        proba *= float(tmp)\n",
    "    return proba\n",
    "\n",
    "#Calculate the porbabilities of a row belonging to each class\n",
    "#then return the class with the bigge\n",
    "def estimate_class(baseline, row):\n",
    "    arow = np.array(row, dtype=np.float64)\n",
    "    p1 = calculate_class_probability(arow, baseline[0][0], baseline[0][1], baseline[0][2])\n",
    "    p2 = calculate_class_probability(arow, baseline[1][0], baseline[1][1], baseline[1][2])\n",
    "    total_rows = baseline[0,0,0] + baseline[0,1,0]\n",
    "    p1 *= (baseline[0,0,0] / total_rows)\n",
    "    p2 *= (baseline[0,1,0] / total_rows)\n",
    "    if (p1 >= p2):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def calculate_accuracy(baseline, rows):\n",
    "    n = len(rows)\n",
    "    v = 0\n",
    "    for row in rows:\n",
    "        c = estimate_class(baseline, row)\n",
    "        if (c == row[-1]):\n",
    "            v += 1\n",
    "    return (float(v/n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac27296",
   "metadata": {},
   "source": [
    "# Tie All Together\n",
    "## Prep the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c35e015",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prep data\n",
    "change_columns_to_int(trainArray, [13, 19, 24, 25, 27, 28, 30, 36, 39, 42, 53, 66, 88])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68a8b558",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data to classes\n",
    "classes = separate_by_class(trainArray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29db94e9",
   "metadata": {},
   "source": [
    "## Split the Data into 80-20 from each class\n",
    "use the 20% as a test for calculating accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "325926fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133639 26727\n",
      "106912 26727\n",
      "11848 2369\n",
      "9479 2369\n",
      "29096\n"
     ]
    }
   ],
   "source": [
    "#split int 80-20 for training-testing\n",
    "import random\n",
    "testSet = []\n",
    "\n",
    "for index in classes:\n",
    "    size = int(len(classes[index]) * 0.2)\n",
    "    print(len(classes[index]), size)\n",
    "    random.shuffle(classes[index])\n",
    "    testSet.extend(classes[index][:size])\n",
    "    classes[index] = classes[index][size:]\n",
    "    print(len(classes[index]), size)\n",
    "random.shuffle(testSet)\n",
    "print(len(testSet))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857ee580",
   "metadata": {},
   "source": [
    "## Calculate the BaseLine classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f1b76d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.125244199996814\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "baseline = summarize_each_class(classes)\n",
    "print(\"time:\", timer()-start)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865942b4",
   "metadata": {},
   "source": [
    "## Test the accuracy of the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "859d192c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "len() of unsized object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m start \u001b[38;5;241m=\u001b[39m timer()\n\u001b[1;32m----> 2\u001b[0m acc \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtestSet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime: \u001b[39m\u001b[38;5;124m\"\u001b[39m, timer()\u001b[38;5;241m-\u001b[39mstart)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy: \u001b[39m\u001b[38;5;124m\"\u001b[39m, acc)\n",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36mcalculate_accuracy\u001b[1;34m(baseline, rows)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(n, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m rows:\n\u001b[1;32m---> 33\u001b[0m     c \u001b[38;5;241m=\u001b[39m \u001b[43mestimate_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (c \u001b[38;5;241m==\u001b[39m row[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]):\n\u001b[0;32m     35\u001b[0m         v \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36mestimate_class\u001b[1;34m(baseline, row)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mestimate_class\u001b[39m(baseline, row):\n\u001b[0;32m     17\u001b[0m     arow \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(row, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m---> 18\u001b[0m     p1 \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_class_probability\u001b[49m\u001b[43m(\u001b[49m\u001b[43marow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     p2 \u001b[38;5;241m=\u001b[39m calculate_class_probability(arow, baseline[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m], baseline[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m], baseline[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m     20\u001b[0m     total_rows \u001b[38;5;241m=\u001b[39m baseline[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m baseline[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m]\n",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36mcalculate_class_probability\u001b[1;34m(row, sizes, means, devs)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_class_probability\u001b[39m(row, sizes, means, devs):\n\u001b[0;32m      4\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (devs[i] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m      7\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: len() of unsized object"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "acc = calculate_accuracy(baseline, testSet)\n",
    "print(\"time: \", timer()-start)\n",
    "print(\"accuracy: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48fe6f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29096\n"
     ]
    }
   ],
   "source": [
    "print(len(testSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b428ab4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[442778 0 0.0 0.0 nan 0.0 0.0 0.0 nan nan 0.0 0.0 nan nan 0.0 0.0 0.0 nan\n",
      " 0.0 nan 0.0 0 18789.707666666694 nan nan nan 0.0 6691 nan 0.0 nan nan nan\n",
      " 0.0 0.0 0.0 nan 0.0 1 nan 0 nan nan 0.0 0.666666666666667\n",
      " 0.9882966183942192 0.0 384 nan 0 nan 0.0 0.0 nan nan nan nan 0 nan nan\n",
      " nan nan 0.120003719057329 0.0 nan nan nan 0.0 0.579194218615039 nan\n",
      " 0.0002730060175267 0.0 nan 0.0 1.0 nan 0.0 1.0 0.0 nan 45.0 nan 45.0 nan\n",
      " 0.0 nan 0.0 0.986207705776588 6 nan nan 6.02301181053365 0.0 0.0 nan 0.0\n",
      " nan 0.9882966183942192 nan 0.666666666666667 nan 0.0 1.0 0.0 nan\n",
      " 0.0138050043140638 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0]\n"
     ]
    }
   ],
   "source": [
    "print(testSet[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f936adf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
