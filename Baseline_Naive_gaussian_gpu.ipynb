{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c67d7e9a",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6c9d718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from timeit import default_timer as timer\n",
    "from numba import jit, njit\n",
    "from numba.typed import List\n",
    "\n",
    "\n",
    "df = pd.read_csv('bank_data_train.csv', skiprows=1)\n",
    "trainArray = df.to_numpy()\n",
    "\n",
    "file = open('bank_data_train.csv')\n",
    "reader = csv.reader(file);\n",
    "file.close()\n",
    "\n",
    "df = pd.read_csv('bank_data_test.csv', skiprows=1)\n",
    "finalTestingData = df.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "212ffdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_str_to_index(dataset, columnIndex):\n",
    "    unique = list()\n",
    "    for row in dataset:\n",
    "        s = str(row[columnIndex])\n",
    "        if (s == 'nan'):\n",
    "            continue\n",
    "        s = s.lower()\n",
    "        if (s not in unique):\n",
    "            unique.append(s)\n",
    "        row[columnIndex] = unique.index(s)\n",
    "\n",
    "def change_columns_to_int(dataset, columns):\n",
    "    for column in columns:\n",
    "        change_str_to_index(dataset, column)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc0507f",
   "metadata": {},
   "source": [
    "# Naiv Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2efe13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate data by class\n",
    "#this function assumes that the last column of the table is the class\n",
    "from math import sqrt\n",
    "from math import exp\n",
    "from math import pi\n",
    "from numba import jit, njit\n",
    "\n",
    "#separate the data into classes according to the last value in each row\n",
    "def separate_by_class(dataset):\n",
    "\tseparated = dict()\n",
    "\tfor i in range(len(dataset)):\n",
    "\t\tvector = dataset[i]\n",
    "\t\tclass_value = vector[-1]\n",
    "\t\tif (class_value not in separated):\n",
    "\t\t\tseparated[class_value] = list()\n",
    "\t\tseparated[class_value].append(vector)\n",
    "\treturn separated\n",
    "\n",
    "\n",
    "#count non nan elements\n",
    "@njit\n",
    "def len_nan(numbers):\n",
    "    return (np.count_nonzero(~np.isnan(numbers)))\n",
    "\n",
    "\n",
    "#claculate the mean of a list of numbers ignoring nan elements\n",
    "@njit\n",
    "def mean_nan(numbers, size):\n",
    "    return np.nansum(numbers)/ size\n",
    "\n",
    "\n",
    "#claculate the standard deviation of a list of numbers ignoring nan elements\n",
    "@njit\n",
    "def stdev_nan(numbers, mean, size):\n",
    "    variance = np.nansum(np.array([(x - mean)**2 for x in numbers], dtype=np.float64)) / size\n",
    "    return sqrt(variance)\n",
    "\n",
    "#get column of 2d array\n",
    "@jit\n",
    "def get_column(matrix, i):\n",
    "    return [row[i] for row in matrix]\n",
    "\n",
    "\n",
    "# Calculate the Gaussian probability distribution function for x\n",
    "@njit\n",
    "def normal(mean, stdev, val):\n",
    "    exponent = exp(-((val-mean)**2 / (2 * stdev**2 )))\n",
    "    return (1 / (sqrt(2 * pi) * stdev)) * exponent\n",
    "\n",
    "\n",
    "# summarise the data for each metric in the dataset\n",
    "# claculate the mean, dev and count for each column\n",
    "def summarize_dataset(dataset, n):\n",
    "    i = 0\n",
    "    sizes = np.zeros(n, dtype = np.float64)\n",
    "    means = np.zeros(n, dtype = np.float64)\n",
    "    devs = np.zeros(n, dtype = np.float64)\n",
    "    for column in zip(*dataset):\n",
    "        arr = np.array(column, dtype=np.float64)\n",
    "        size = len_nan(arr)\n",
    "        mean = mean_nan(arr, size)\n",
    "        dev = stdev_nan(arr, mean, size)\n",
    "        sizes[i] = size\n",
    "        means[i] = mean\n",
    "        devs[i] = dev\n",
    "        i += 1\n",
    "    return (sizes, means, devs)\n",
    "\n",
    "#substitute each class with the summarized values\n",
    "def summarize_each_class(separated):\n",
    "    summaries = dict()\n",
    "    n = len(separated[0][0])\n",
    "    for class_value, rows in separated.items():\n",
    "        summaries[class_value] = summarize_dataset(rows, n)\n",
    "    return summaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4992b16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#P(class=0|X1,X2) = P(X1|class=0) * P(X2|class=0) * P(class=0)\n",
    "# Calculate the probabilities of row belonging to a class\n",
    "@njit\n",
    "def calculate_class_probability(row, sizes, means, devs):\n",
    "    proba = 1.0\n",
    "    for i in range(1, len(row), 1):\n",
    "        if (devs[i] == 0):\n",
    "            continue\n",
    "        tmp = normal(means[i], devs[i], row[i])\n",
    "        if (np.isnan(tmp)):\n",
    "            tmp = 1.0\n",
    "        proba *= float(tmp)\n",
    "    return proba\n",
    "\n",
    "#Calculate the porbabilities of a row belonging to each class\n",
    "#then return the class with the bigge\n",
    "def estimate_class(baseline, row):\n",
    "    arow = np.array(row, dtype=np.float64)\n",
    "    p1 = calculate_class_probability(arow, baseline[0][0], baseline[0][1], baseline[0][2])\n",
    "    p2 = calculate_class_probability(arow, baseline[1][0], baseline[1][1], baseline[1][2])\n",
    "    total_rows = baseline[0][0][0] + baseline[0][1][0]\n",
    "    p1 *= (baseline[0][0][0] / total_rows)\n",
    "    p2 *= (baseline[0][1][0] / total_rows)\n",
    "    if (p1 >= p2):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def calculate_accuracy(baseline, rows):\n",
    "    n = len(rows)\n",
    "    v = 0\n",
    "    for row in rows:\n",
    "        c = estimate_class(baseline, row)\n",
    "        if (c == row[-1]):\n",
    "            v += 1\n",
    "    return (float(v/n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac27296",
   "metadata": {},
   "source": [
    "# Tie All Together\n",
    "## Prep the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c35e015",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prep data\n",
    "change_columns_to_int(trainArray, [13, 19, 24, 25, 27, 28, 30, 36, 39, 42, 53, 66, 88])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68a8b558",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data to classes\n",
    "classes = separate_by_class(trainArray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6342a1b5",
   "metadata": {},
   "source": [
    "## Split the Data into 80-20 from each class\n",
    "use the 20% as a test for calculating accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "325926fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326264 65252\n",
      "261012 65252\n",
      "28925 5785\n",
      "23140 5785\n",
      "71037\n"
     ]
    }
   ],
   "source": [
    "#split int 80-20 for training-testing\n",
    "import random\n",
    "testSet = []\n",
    "\n",
    "for index in classes:\n",
    "    size = int(len(classes[index]) * 0.2)\n",
    "    print(len(classes[index]), size)\n",
    "    random.shuffle(classes[index])\n",
    "    testSet.extend(classes[index][:size])\n",
    "    classes[index] = classes[index][size:]\n",
    "    print(len(classes[index]), size)\n",
    "random.shuffle(testSet)\n",
    "print(len(testSet))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80a4f3a",
   "metadata": {},
   "source": [
    "## Calculate the BaseLine classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f1b76d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15.293562999999267\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "baseline = summarize_each_class(classes)\n",
    "print(\"time:\", timer()-start)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cf826e",
   "metadata": {},
   "source": [
    "## Test the accuracy of the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "859d192c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time:  1.5757622999954037\n",
      "accuracy:  0.7334065346228023\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "acc = calculate_accuracy(baseline, testSet)\n",
    "print(\"time: \", timer()-start)\n",
    "print(\"accuracy: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1d97e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
