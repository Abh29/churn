{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79c2ebe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from timeit import default_timer as timer\n",
    "from numba import jit, njit\n",
    "from numba.typed import List\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49cb2eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('bank_data_train.csv', skiprows=1)\n",
    "trainArray = df.to_numpy()\n",
    "\n",
    "file = open('bank_data_train.csv')\n",
    "reader = csv.reader(file);\n",
    "file.close()\n",
    "\n",
    "df = pd.read_csv('bank_data_test.csv', skiprows=1)\n",
    "finalTestingData = df.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "212ffdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_str_to_index(dataset, columnIndex):\n",
    "    unique = list()\n",
    "    for row in dataset:\n",
    "        s = str(row[columnIndex])\n",
    "        if (s == 'nan'):\n",
    "            continue\n",
    "        s = s.lower()\n",
    "        if (s not in unique):\n",
    "            unique.append(s)\n",
    "        row[columnIndex] = unique.index(s)\n",
    "\n",
    "def change_columns_to_int(dataset, columns):\n",
    "    for column in columns:\n",
    "        change_str_to_index(dataset, column)\n",
    "\n",
    "#separate the data into classes according to the last value in each row\n",
    "def separate_by_class(dataset):\n",
    "\tseparated = dict()\n",
    "\tfor i in range(len(dataset)):\n",
    "\t\tvector = dataset[i]\n",
    "\t\tclass_value = vector[-1]\n",
    "\t\tif (class_value not in separated):\n",
    "\t\t\tseparated[class_value] = list()\n",
    "\t\tseparated[class_value].append(vector)\n",
    "\treturn separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c35e015",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prep data\n",
    "change_columns_to_int(trainArray, [13, 19, 24, 25, 27, 28, 30, 36, 39, 42, 53, 66, 88])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68a8b558",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data to classes\n",
    "classes = separate_by_class(trainArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52903b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326264 65252\n",
      "326264 65252\n",
      "28925 5785\n",
      "28925 5785\n",
      "71037\n",
      "284152\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "testSet = []\n",
    "trainSet = []\n",
    "\n",
    "for index in classes:\n",
    "    size = int(len(classes[index]) * 0.2)\n",
    "    print(len(classes[index]), size)\n",
    "    random.shuffle(classes[index])\n",
    "    testSet.extend(classes[index][:size])\n",
    "    trainSet.extend(classes[index][size:])\n",
    "    print(len(classes[index]), size)\n",
    "random.shuffle(testSet)\n",
    "random.shuffle(trainSet)\n",
    "print(len(testSet))\n",
    "print(len(trainSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de2f3970",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = [row[:-1] for row in trainSet]\n",
    "train_y = [row[-1] for row in trainSet]\n",
    "test_x = [row[:-1] for row in testSet]\n",
    "test_y = [row[-1] for row in testSet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f261d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp = imp.fit(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "438e7c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_imp = imp.transform(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b5d44f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = MLPClassifier(random_state=1, max_iter=300).fit(train_x_imp[:100000], train_y[:100000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e98c7c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time:  66.41475630000059\n",
      "accuracy =  0.918563565465884\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "n = len(test_x)\n",
    "v = 0\n",
    "for i in range(n):\n",
    "    test_imp = imp.transform(test_x[i].reshape(1, -1))\n",
    "    prediction = classifier.predict(test_imp)\n",
    "    if (prediction[0] == test_y[i]):\n",
    "        v += 1\n",
    "print(\"time: \", timer() - start)\n",
    "print(\"accuracy = \", v / float(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12313ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "X_train = [[0, 0, np.nan], [np.nan, 1, 1]]\n",
    "Y_train = [0, 1]\n",
    "X_test_1 = [0, 0, np.nan]\n",
    "X_test_2 = [0, np.nan, np.nan]\n",
    "X_test_3 = [np.nan, 1, 1]\n",
    "\n",
    "# Create our imputer to replace missing values with the mean e.g.\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp = imp.fit(X_train)\n",
    "\n",
    "# Impute our data, then train\n",
    "X_train_imp = imp.transform(X_train)\n",
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "clf = clf.fit(X_train_imp, Y_train)\n",
    "\n",
    "for X_test in [X_test_1, X_test_2, X_test_3]:\n",
    "    # Impute each test item, then predict\n",
    "    X_test_imp = imp.transform(X_test)\n",
    "    print(X_test, '->', clf.predict(X_test_imp))\n",
    "\n",
    "# Results\n",
    "[0, 0, nan] -> [0]\n",
    "[0, nan, nan] -> [0]\n",
    "[nan, 1, 1] -> [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38d5e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=100, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2d3d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a592dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(random_state=1, max_iter=300).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52db548d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict_proba(X_test[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b07d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(X_test[:5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eed016c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d0d247",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
